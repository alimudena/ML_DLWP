{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gpds\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gpds\\OneDrive - Universidad Politécnica de Madrid\\0_ML\\DLWP\\ML_DLWP\\Chapter_4_2_validation_data.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gpds/OneDrive%20-%20Universidad%20Polit%C3%A9cnica%20de%20Madrid/0_ML/DLWP/ML_DLWP/Chapter_4_2_validation_data.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gpds/OneDrive%20-%20Universidad%20Polit%C3%A9cnica%20de%20Madrid/0_ML/DLWP/ML_DLWP/Chapter_4_2_validation_data.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m model \u001b[39m=\u001b[39m get_model()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gpds/OneDrive%20-%20Universidad%20Polit%C3%A9cnica%20de%20Madrid/0_ML/DLWP/ML_DLWP/Chapter_4_2_validation_data.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(training_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gpds/OneDrive%20-%20Universidad%20Polit%C3%A9cnica%20de%20Madrid/0_ML/DLWP/ML_DLWP/Chapter_4_2_validation_data.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m validation_score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(validation_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gpds/OneDrive%20-%20Universidad%20Polit%C3%A9cnica%20de%20Madrid/0_ML/DLWP/ML_DLWP/Chapter_4_2_validation_data.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Ajuste del modelo y reentrenar, avaluar, volver a ajustar ect. Tras reajustar los hiperparámetros, es habitual entrenar el modelo desde cero ocnt odos los datos disponibles que no sean de prieba\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "num_validation_samples = 1000\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "np.random.shuffle(train_data) #se mezclan los datos\n",
    "\n",
    "validation_data = train_data[:num_validation_samples]\n",
    "data = train_data[num_validation_samples:]\n",
    "\n",
    "training_data = data[:] #definimos el conjunto de entrenamiento\n",
    "\n",
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape = (10000,)))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(46, activation = 'softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'rmsprop', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "\n",
    "\n",
    "# Ajuste del modelo y reentrenar, avaluar, volver a ajustar ect. Tras reajustar los hiperparámetros, es habitual entrenar el modelo desde cero ocnt odos los datos disponibles que no sean de prieba\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "model.train(np.concatenate([train_data, validation_data]))\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
